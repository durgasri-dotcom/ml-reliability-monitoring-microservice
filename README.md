# ML Reliability Monitoring Microservice

## ğŸ“Œ Project Overview

This project is an **end-to-end analytics platform** designed to monitor, analyze, and improve **system reliability and performance** using simulated large-scale device telemetry and request-level data.

---

The platform models how modern engineering teams at companies like Netflix, Google, or Amazon monitor system health, detect failures early, and make data-driven reliability decisions.
This project mirrors real-world reliability analytics workflows used by large-scale
engineering teams to maintain system health, prevent outages, and ensure consistent
user experience at scale.

---

## ğŸ¯ Key Objectives

- Monitor system reliability across thousands of devices
- Detect early signs of performance degradation
- Enable fast, actionable insights for engineering stakeholders
- Demonstrate production-style analytics and ML workflows

---

## ğŸ“Š Reliability KPIs & Metrics

The following **core reliability KPIs** are defined, documented, and analyzed:

- **Request Success Rate**
- **Error Rate**
- **Average & P95 Latency**
- **Failure Frequency**
- **Trend Indicators (time-based degradation patterns)**

These KPIs are structured to support analysis across:

- Device types
- Regions
- Time windows (daily trends)

---

## ğŸ—ï¸ Data Modeling & Architecture

- Designed **analytics-ready data models** to enable reusable analysis
- Scaled to **5,000+ device records** with time-series telemetry
- Structured datasets for compatibility with BI tools and ML pipelines

**Data Sources**

- Simulated device telemetry
- Request-level performance metrics
- Time-based system logs

---

## ğŸ” Advanced Analytics & Signal Detection

- Performed **request-pattern analysis** to uncover new signals correlated with reliability degradation
- Identified abnormal latency and failure patterns across devices
- Enabled proactive detection instead of reactive monitoring

---

## ğŸ¤– Anomaly Detection (ML)

- Implemented anomaly detection using:
  - Rolling baselines
  - Statistical thresholds
  - Machine learningâ€“ready features
- Used PCA-based visualization for anomaly interpretation
- Designed the system to be extendable to Isolation Forest and other ML models

---

## ğŸ“ˆ Visualization & Decision Support

- Delivered **interactive dashboards** designed for fast decision-making
- Visualized:
  - Latency distributions
  - Failure trends
  - Anomaly clusters
- Dashboards are optimized for **engineering and reliability teams**

### Dashboard Demo

![Dashboard Demo](screenshots/dashboard_demo.gif)

---

## ğŸ“ˆ Business Impact

- Enabled early detection of reliability degradation before customer impact
- Reduced mean time to detection (MTTD) through proactive anomaly identification
- Provided engineering teams with actionable, KPI-driven insights for decision-making

---

## ğŸ§° Tech Stack

- **Python** (pandas, numpy, scikit-learn)
- **Streamlit** (analytics dashboard)
- **Matplotlib / Seaborn** (visualizations)
- **Machine Learning** (PCA, statistical anomaly detection)
- **Git & GitHub** (version control)

---

## ğŸš€ How to Run Locally

```bash
pip install -r requirements.txt
streamlit run src/dashboard.py

---

## ğŸ‘¤ Author
**Durga**
Analytics & Machine Learning Engineer
Specialized in Reliability, Performance & System Analytics

```
